{"case_id": "NAT_0001", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"with many retrieved passages being [BLANK] and reused across multiple inferences.\"?", "gold": "uninformative", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 11, "relevant_text": "with many retrieved passages being uninformative and reused across multiple inferences.", "slice": "natural_answerable"}
{"case_id": "NAT_0002", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"In contrast, we explore a setting where both parametric and [BLANK] memory components are pre-trained and pre-loaded with extensive knowledge.\"?", "gold": "non-parametric", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 12, "relevant_text": "In contrast, we explore a setting where both parametric and non-parametric memory components are pre-trained and pre-loaded with extensive knowledge.", "slice": "natural_answerable"}
{"case_id": "NAT_0003", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"In addition, our optimization framework for large context [BLANK] extend the context size of LLMs by16 ×.\"?", "gold": "enablesrefragto", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 3, "relevant_text": "In addition, our optimization framework for large context enablesREFRAGto extend the context size of LLMs by16 ×.", "slice": "natural_answerable"}
{"case_id": "NAT_0004", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"igure 1) while preserving the [BLANK] nature of the decoder, thereby supporting multi-turn and agentic applications.\"?", "gold": "autoregressive", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 15, "relevant_text": "igure 1) while preserving the autoregressive nature of the decoder, thereby supporting multi-turn and agentic applications.", "slice": "natural_answerable"}
{"case_id": "NAT_0005", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"Unfortunately, this approach does not scale with the number of documents, since the [BLANK] in the encoder results in a quadratic complexity with respect to the number of documents.\"?", "gold": "self-attention", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 22, "relevant_text": "Unfortunately, this approach does not scale with the number of documents, since the self-attention in the encoder results in a quadratic complexity with respect to the number of documents.", "slice": "natural_answerable"}
{"case_id": "NAT_0006", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"3 [BLANK] To align the encoder and decoder, we follow the work of Yen et al.\"?", "gold": "methodology", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 26, "relevant_text": "3 Methodology To align the encoder and decoder, we follow the work of Yen et al.", "slice": "natural_answerable"}
{"case_id": "NAT_0007", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"Then, a [BLANK] model generates the answer, taking as input the re- trieved passages in addition to the question.\"?", "gold": "sequence-to-sequence", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 8, "relevant_text": "Then, a sequence-to-sequence model generates the answer, taking as input the re- trieved passages in addition to the question.", "slice": "natural_answerable"}
{"case_id": "NAT_0008", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"The examples show that a low-quality retriever is prone to introducing a [BLANK] amount of irrelevant information, impeding the generators from acquiring accurate knowledge and potentially misleading them.\"?", "gold": "substantial", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 6, "relevant_text": "The examples show that a low-quality retriever is prone to introducing a substantial amount of irrelevant information, impeding the generators from acquiring accurate knowledge and potentially misleading them.", "slice": "natural_answerable"}
{"case_id": "NAT_0009", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"The overall probability [BLANK] is a weighted combination P(x) =PK k=1πkN(x;µk,Σk), where πksignifies the mixture weight for the kthGaussian distribution.\"?", "gold": "distribution", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 28, "relevant_text": "The overall probability distribution is a weighted combination P(x) =PK k=1πkN(x;µk,Σk), where πksignifies the mixture weight for the kthGaussian distribution.", "slice": "natural_answerable"}
{"case_id": "NAT_0010", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"RAG is ideal when the total number of [BLANK] in a data source is too large to include in a single prompt to the LLM, i.e.\"?", "gold": "records", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 14, "relevant_text": "RAG is ideal when the total number of records in a data source is too large to include in a single prompt to the LLM, i.e.", "slice": "natural_answerable"}
{"case_id": "NAT_0011", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"Reflection tokens, inspired by reward models used in [BLANK] learning (Ziegler et al., 2019; Ouyang et al., 2022), are inserted offline into the original corpus by a trained critic model.\"?", "gold": "reinforcement", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 14, "relevant_text": "Reflection tokens, inspired by reward models used in reinforcement learning (Ziegler et al., 2019; Ouyang et al., 2022), are inserted offline into the original corpus by a trained critic model.", "slice": "natural_answerable"}
{"case_id": "NAT_0012", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"This approach first uses one LLM to generate a diverse set of global [BLANK] questions based on corpus-sp\"?", "gold": "sensemaking", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 11, "relevant_text": "This approach first uses one LLM to generate a diverse set of global sensemaking questions based on corpus-sp", "slice": "natural_answerable"}
{"case_id": "NAT_0013", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"However, most existing methods target generic LLM tasks with long context and are largely [BLANK] to our work.\"?", "gold": "orthogonal", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 9, "relevant_text": "However, most existing methods target generic LLM tasks with long context and are largely orthogonal to our work.", "slice": "natural_answerable"}
{"case_id": "NAT_0014", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"(2019): •[BLANK] (Kwiatkowski et al., 2019) contains questions corresponding to Google search queries.\"?", "gold": "naturalquestions", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 24, "relevant_text": "(2019): •NaturalQuestions (Kwiatkowski et al., 2019) contains questions corresponding to Google search queries.", "slice": "natural_answerable"}
{"case_id": "NAT_0015", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"ting the LM’s [BLANK], REPLUG treats the language model as a black box and augments it with a frozen or tunable retriever.\"?", "gold": "parameters", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 5, "relevant_text": "ting the LM’s parameters, REPLUG treats the language model as a black box and augments it with a frozen or tunable retriever.", "slice": "natural_answerable"}
{"case_id": "NAT_0016", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"of retrieved passages prepended to input, or pre-train a retriever and LM jointly, followed by few- shot [BLANK] on task datasets (Izacard et al., 2022b).\"?", "gold": "fine-tuning", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 19, "relevant_text": "of retrieved passages prepended to input, or pre-train a retriever and LM jointly, followed by few- shot fine-tuning on task datasets (Izacard et al., 2022b).", "slice": "natural_answerable"}
{"case_id": "NAT_0017", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"3 2.2 Training [BLANK] for the retriever In this section, we discuss four diﬀerent loss functions to train the retriever jointly with the langu\"?", "gold": "objectives", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 22, "relevant_text": "3 2.2 Training objectives for the retriever In this section, we discuss four diﬀerent loss functions to train the retriever jointly with the langu", "slice": "natural_answerable"}
{"case_id": "NAT_0018", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"We then minimize the [BLANK] between pattn(dk), and the distribution pretrfrom the retriever deﬁned in Equation 1: KL(pattn∥pretr) =K∑ k=1pa\"?", "gold": "kl-divergence", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 28, "relevant_text": "We then minimize the KL-divergence between pattn(dk), and the distribution pretrfrom the retriever deﬁned in Equation 1: KL(pattn∥pretr) =K∑ k=1pa", "slice": "natural_answerable"}
{"case_id": "NAT_0019", "query": "According to the paper 'recomp improving retrieval augmented lms with compression and selective augmentation', what exact term completes this statement: \"(3) Faithful :sshould be a faithful and [BLANK] summary of the input document set (i.e., smust be entailed by the input document set ( [d1, d2, ...dN])).\"?", "gold": "interpretable", "relevant_doc_id": "2310.04408__recomp_improving_retrieval_augmented_lms_with_compression_and_selective_augmentation.txt", "relevant_chunk_id": 18, "relevant_text": "(3) Faithful :sshould be a faithful and interpretable summary of the input document set (i.e., smust be entailed by the input document set ( [d1, d2, ...dN])).", "slice": "natural_answerable"}
{"case_id": "NAT_0020", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"We introduce a method to train an arbitrary LM to learn to use retrieval on-demand for diverse [BLANK] queries and introduce controlled generation guided by reflections tokens to further improve generation quality and attributions.\"?", "gold": "instruction-following", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 21, "relevant_text": "We introduce a method to train an arbitrary LM to learn to use retrieval on-demand for diverse instruction-following queries and introduce controlled generation guided by reflections tokens to further improve generation quality and attributions.", "slice": "natural_answerable"}
{"case_id": "NAT_0021", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"For example, in the case of question answering, the query [BLANK] to the question and the model needs to generate the answer.\"?", "gold": "corresponds", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 16, "relevant_text": "For example, in the case of question answering, the query corresponds to the question and the model needs to generate the answer.", "slice": "natural_answerable"}
{"case_id": "NAT_0022", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"Recent work on LLM refinement (Dhuliawala et al., 2023; Madaan et al., 2023; Paul et al., 2023) prompts a model to generate task output, natural language feedback and refined task output [BLANK], but at the cost of inference efficiency.\"?", "gold": "iteratively", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 27, "relevant_text": "Recent work on LLM refinement (Dhuliawala et al., 2023; Madaan et al., 2023; Paul et al., 2023) prompts a model to generate task output, natural language feedback and refined task output iteratively, but at the cost of inference efficiency.", "slice": "natural_answerable"}
{"case_id": "NAT_0023", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"Results show that we achieve30 .75×TTFT [BLANK] without loss in perplexity which is3 .75×than previous method.\"?", "gold": "acceleration", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 16, "relevant_text": "Results show that we achieve30 .75×TTFT acceleration without loss in perplexity which is3 .75×than previous method.", "slice": "natural_answerable"}
{"case_id": "NAT_0024", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the [BLANK] memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever.\"?", "gold": "non-parametric", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 2, "relevant_text": "We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever.", "slice": "natural_answerable"}
{"case_id": "NAT_0025", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"We argue that specialized techniques exploiting the unique structure and sparsity inherent in RAG contexts can [BLANK] reduce memory and computational overhead.\"?", "gold": "substantially", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 10, "relevant_text": "We argue that specialized techniques exploiting the unique structure and sparsity inherent in RAG contexts can substantially reduce memory and computational overhead.", "slice": "natural_answerable"}
{"case_id": "NAT_0026", "query": "According to the paper 'recomp improving retrieval augmented lms with compression and selective augmentation', what exact term completes this statement: \"If the retrieved documents are irrelevant to the input or offer no additional information to LM, our compressor can return an empty string, [BLANK] selective augmentation.\"?", "gold": "implementing", "relevant_doc_id": "2310.04408__recomp_improving_retrieval_augmented_lms_with_compression_and_selective_augmentation.txt", "relevant_chunk_id": 2, "relevant_text": "If the retrieved documents are irrelevant to the input or offer no additional information to LM, our compressor can return an empty string, implementing selective augmentation.", "slice": "natural_answerable"}
{"case_id": "NAT_0027", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"This suggests that selecting the most relevant information for [BLANK] tasks is still crucial.\"?", "gold": "knowledge-intensive", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 13, "relevant_text": "This suggests that selecting the most relevant information for knowledge-intensive tasks is still crucial.", "slice": "natural_answerable"}
{"case_id": "NAT_0028", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"This avoids the need to run [BLANK] forward passes once the candidate set Yhas been generated.\"?", "gold": "additional", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 28, "relevant_text": "This avoids the need to run additional forward passes once the candidate set Yhas been generated.", "slice": "natural_answerable"}
{"case_id": "NAT_0029", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"vector embeddings presents a challenge for traditional GMMs, as dis- tance metrics may behave poorly when used to measure similarity in [BLANK] spaces (Ag- garwal et al., 2001).\"?", "gold": "high-dimensional", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 29, "relevant_text": "vector embeddings presents a challenge for traditional GMMs, as dis- tance metrics may behave poorly when used to measure similarity in high-dimensional spaces (Ag- garwal et al., 2001).", "slice": "natural_answerable"}
{"case_id": "NAT_0030", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"model parameters), for both reducing LM perplexity and and im- proving in-context learning [BLANK].\"?", "gold": "performance", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 11, "relevant_text": "model parameters), for both reducing LM perplexity and and im- proving in-context learning performance.", "slice": "natural_answerable"}
{"case_id": "NAT_0031", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"FRAG achieves better performance than LLaMA without incurring higher latency in the downstream [BLANK].\"?", "gold": "applications", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 17, "relevant_text": "FRAG achieves better performance than LLaMA without incurring higher latency in the downstream applications.", "slice": "natural_answerable"}
{"case_id": "NAT_0032", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"This structure enables RAPTOR to load into an LLM’s context chunks [BLANK] the text at different levels so that it can effectively and efficiently answer questions at different levels.\"?", "gold": "representing", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 8, "relevant_text": "This structure enables RAPTOR to load into an LLM’s context chunks representing the text at different levels so that it can effectively and efficiently answer questions at different levels.", "slice": "natural_answerable"}
{"case_id": "NAT_0033", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"Atlasachieves strong downstream performance in both few-shot and [BLANK] settings.\"?", "gold": "resource-rich", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 10, "relevant_text": "Atlasachieves strong downstream performance in both few-shot and resource-rich settings.", "slice": "natural_answerable"}
{"case_id": "NAT_0034", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"In real [BLANK] (e.g., RAG), the context is the dominating part of the input (i.e., s≫q) and hence the overall input to the decod\"?", "gold": "applications", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 21, "relevant_text": "In real applications (e.g., RAG), the context is the dominating part of the input (i.e., s≫q) and hence the overall input to the decod", "slice": "natural_answerable"}
{"case_id": "NAT_0035", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"Moreover, [BLANK] citations for each segment with its self-assessment of whether the output is supported by the passage, leading to easier fact verification.\"?", "gold": "self-ragprovides", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 13, "relevant_text": "Moreover, SELF-RAGprovides citations for each segment with its self-assessment of whether the output is supported by the passage, leading to easier fact verification.", "slice": "natural_answerable"}
{"case_id": "NAT_0036", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"(2020) in- troduced retrieval augmented [BLANK] models for open domain question answering.\"?", "gold": "generative", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 16, "relevant_text": "(2020) in- troduced retrieval augmented generative models for open domain question answering.", "slice": "natural_answerable"}
{"case_id": "NAT_0037", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"ve models, and multiple [BLANK] have been proposed to address this limitation (Clark and Gardner, 2018; Min et al., 2019a).\"?", "gold": "techniques", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 7, "relevant_text": "ve models, and multiple techniques have been proposed to address this limitation (Clark and Gardner, 2018; Min et al., 2019a).", "slice": "natural_answerable"}
{"case_id": "NAT_0038", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"These texts are then embedded using SBERT, a BERT-based encoder ( [BLANK]1 ) (Reimers & Gurevych, 2019).\"?", "gold": "multi-qa-mpnet-base-cos-v", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 23, "relevant_text": "These texts are then embedded using SBERT, a BERT-based encoder ( multi-qa-mpnet-base-cos-v1 ) (Reimers & Gurevych, 2019).", "slice": "natural_answerable"}
{"case_id": "NAT_0039", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"Both methods require updating the model [BLANK] through gradient descent, which cannot be applied to black-box LMs.\"?", "gold": "parameters", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 18, "relevant_text": "Both methods require updating the model parameters through gradient descent, which cannot be applied to black-box LMs.", "slice": "natural_answerable"}
{"case_id": "NAT_0040", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"o substantial improvements over a conventional RAG baseline for both the [BLANK] and diversity of generated answers.\"?", "gold": "comprehensiveness", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 4, "relevant_text": "o substantial improvements over a conventional RAG baseline for both the comprehensiveness and diversity of generated answers.", "slice": "natural_answerable"}
{"case_id": "NAT_0041", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"This is particularly relevant for thematic questions that require integrating knowledge from multiple parts of a text, such as [BLANK] an entire book, as in the NarrativeQA dataset (Ko ˇcisk`y et al., 2018).\"?", "gold": "understanding", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 7, "relevant_text": "This is particularly relevant for thematic questions that require integrating knowledge from multiple parts of a text, such as understanding an entire book, as in the NarrativeQA dataset (Ko ˇcisk`y et al., 2018).", "slice": "natural_answerable"}
{"case_id": "NAT_0042", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"However, in order to produce a fair evaluation, our method avoids generating the questions directly from the corpus itself (as an alternative [BLANK], one can use a subset of the corpus held out from subsequen\"?", "gold": "implementation", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 23, "relevant_text": "However, in order to produce a fair evaluation, our method avoids generating the questions directly from the corpus itself (as an alternative implementation, one can use a subset of the corpus held out from subsequen", "slice": "natural_answerable"}
{"case_id": "NAT_0043", "query": "According to the paper 'recomp improving retrieval augmented lms with compression and selective augmentation', what exact term completes this statement: \"1arXiv:2310.04408v1 [cs.CL] 6 Oct 2023 RECOMP during inference moved from Smyrna, [BLANK], to Nissan's facility in Canton, M\"?", "gold": "tennessee", "relevant_doc_id": "2310.04408__recomp_improving_retrieval_augmented_lms_with_compression_and_selective_augmentation.txt", "relevant_chunk_id": 7, "relevant_text": "1arXiv:2310.04408v1 [cs.CL] 6 Oct 2023 RECOMP during inference moved from Smyrna, Tennessee, to Nissan's facility in Canton, M", "slice": "natural_answerable"}
{"case_id": "NAT_0044", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"Code to run experiments with RAG has been open-sourced as part of the HuggingFace Transform- ers Library [ 66] and can be found at https://github.com/huggingface/[BLANK]/blob/master/ examples/rag/ .\"?", "gold": "transformers", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 16, "relevant_text": "Code to run experiments with RAG has been open-sourced as part of the HuggingFace Transform- ers Library [ 66] and can be found at https://github.com/huggingface/transformers/blob/master/ examples/rag/ .", "slice": "natural_answerable"}
{"case_id": "NAT_0045", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"For the retrieval of support passages, we consider two methods: BM25 ([BLANK] et al., 1995) and DPR (Karpukhin et al., 2020).\"?", "gold": "robertson", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 19, "relevant_text": "For the retrieval of support passages, we consider two methods: BM25 (Robertson et al., 1995) and DPR (Karpukhin et al., 2020).", "slice": "natural_answerable"}
{"case_id": "NAT_0046", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"3.1.1 Source [BLANK] →Text Chunks To start, the documents in the corpus are split into text chunks.\"?", "gold": "documents", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 31, "relevant_text": "3.1.1 Source Documents →Text Chunks To start, the documents in the corpus are split into text chunks.", "slice": "natural_answerable"}
{"case_id": "NAT_0047", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"In ad- dition, versions of the GraphRAG approach are also available as extensions to multiple open- source libraries, including LangChain (LangChain, 2024), LlamaIndex (LlamaIndex, 2024), Nebu- laGraph ([BLANK], 2024), and Neo4J (Neo4J, 2024).\"?", "gold": "nebulagraph", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 13, "relevant_text": "In ad- dition, versions of the GraphRAG approach are also available as extensions to multiple open- source libraries, including LangChain (LangChain, 2024), LlamaIndex (LlamaIndex, 2024), Nebu- laGraph (NebulaGraph, 2024), and Neo4J (Neo4J, 2024).", "slice": "natural_answerable"}
{"case_id": "NAT_0048", "query": "According to the paper 'recomp improving retrieval augmented lms with compression and selective augmentation', what exact term completes this statement: \"We summarize the key ideas for our two [BLANK], extractive compressors and abstractive compressor here, and discuss their training schemes formally in Section 3.\"?", "gold": "compressors", "relevant_doc_id": "2310.04408__recomp_improving_retrieval_augmented_lms_with_compression_and_selective_augmentation.txt", "relevant_chunk_id": 19, "relevant_text": "We summarize the key ideas for our two compressors, extractive compressors and abstractive compressor here, and discuss their training schemes formally in Section 3.", "slice": "natural_answerable"}
{"case_id": "NAT_0049", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"[BLANK] Generation RAG (Lewis et al., 2020; Guu et al., 2020) is regarded as a useful method to address the issues above, which enhances the input questions of generative LMs with retrieved documents.\"?", "gold": "retrieval-augmented", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 18, "relevant_text": "Retrieval-Augmented Generation RAG (Lewis et al., 2020; Guu et al., 2020) is regarded as a useful method to address the issues above, which enhances the input questions of generative LMs with retrieved documents.", "slice": "natural_answerable"}
{"case_id": "NAT_0050", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"For this [BLANK] ability to emerge, the key ingredients are scaling both the parameter count of the model, and the size of the training data.\"?", "gold": "generalisation", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 3, "relevant_text": "For this generalisation ability to emerge, the key ingredients are scaling both the parameter count of the model, and the size of the training data.", "slice": "natural_answerable"}
{"case_id": "NAT_0051", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"The tree traversal method traverses the tree [BLANK], pruning and selecting the most relevant nodes at each level.\"?", "gold": "layer-by-layer", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 25, "relevant_text": "The tree traversal method traverses the tree layer-by-layer, pruning and selecting the most relevant nodes at each level.", "slice": "natural_answerable"}
{"case_id": "NAT_0052", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"Given an input query and the retrieved documents from any retriever, a [BLANK] retrieval evaluator is constructed to estimate the relevance score of retrieved d\"?", "gold": "lightweight", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 26, "relevant_text": "Given an input query and the retrieved documents from any retriever, a lightweight retrieval evaluator is constructed to estimate the relevance score of retrieved d", "slice": "natural_answerable"}
{"case_id": "NAT_0053", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"that answers do not [BLANK] to spans in support documents, thus requiring ab- stractive models.\"?", "gold": "correspond", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 15, "relevant_text": "that answers do not correspond to spans in support documents, thus requiring ab- stractive models.", "slice": "natural_answerable"}
{"case_id": "NAT_0054", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"Empirical results on six tasks, including reasoning and long-form generation, demonstrate that SELF- RAGsignificantly outperforms pre-trained and [BLANK] LLMs that have more parameters and widely adopted RAG approaches with higher citation accuracy.\"?", "gold": "instruction-tuned", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 17, "relevant_text": "Empirical results on six tasks, including reasoning and long-form generation, demonstrate that SELF- RAGsignificantly outperforms pre-trained and instruction-tuned LLMs that have more parameters and widely adopted RAG approaches with higher citation accuracy.", "slice": "natural_answerable"}
{"case_id": "NAT_0055", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"This approach offers three main advantages: 1) It shortens the decoder’s input length, improving token [BLANK] ef\"?", "gold": "allocation", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 13, "relevant_text": "This approach offers three main advantages: 1) It shortens the decoder’s input length, improving token allocation ef", "slice": "natural_answerable"}
{"case_id": "NAT_0056", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"For instance, REPLUG can improve Codex (175B) performance on MMLU by 4.5%, achieving compa- rable results to the 540B, [BLANK] Flan-PaLM.\"?", "gold": "instruction-finetuned", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 10, "relevant_text": "For instance, REPLUG can improve Codex (175B) performance on MMLU by 4.5%, achieving compa- rable results to the 540B, instruction-finetuned Flan-PaLM.", "slice": "natural_answerable"}
{"case_id": "NAT_0057", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"Some [BLANK] use subgraphs, elements of the graph, or properties of the graph structure dire\"?", "gold": "techniques", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 19, "relevant_text": "Some techniques use subgraphs, elements of the graph, or properties of the graph structure dire", "slice": "natural_answerable"}
{"case_id": "NAT_0058", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"triever inREPLUG by using the LM itself to provide [BLANK] about which documents should be retrieved.\"?", "gold": "supervision", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 29, "relevant_text": "triever inREPLUG by using the LM itself to provide supervision about which documents should be retrieved.", "slice": "natural_answerable"}
{"case_id": "NAT_0059", "query": "According to the paper 'recomp improving retrieval augmented lms with compression and selective augmentation', what exact term completes this statement: \"For language modelling, both trained compressors achieve a compression ratio of 25% with minimal [BLANK] drop.\"?", "gold": "performance", "relevant_doc_id": "2310.04408__recomp_improving_retrieval_augmented_lms_with_compression_and_selective_augmentation.txt", "relevant_chunk_id": 15, "relevant_text": "For language modelling, both trained compressors achieve a compression ratio of 25% with minimal performance drop.", "slice": "natural_answerable"}
{"case_id": "NAT_0060", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"As shown in the following section, an advantage of dense retrievers is that both query and document encoders can be trained without document annotation, using standard techniques such as gradient descent and [BLANK].\"?", "gold": "distillation", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 20, "relevant_text": "As shown in the following section, an advantage of dense retrievers is that both query and document encoders can be trained without document annotation, using standard techniques such as gradient descent and distillation.", "slice": "natural_answerable"}
{"case_id": "NAT_0061", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"Eventually, when it cannot [BLANK] make a correct or incorrect judgment, a soft and balanced action Ambiguous which combines both of them is triggered.\"?", "gold": "confidently", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 28, "relevant_text": "Eventually, when it cannot confidently make a correct or incorrect judgment, a soft and balanced action Ambiguous which combines both of them is triggered.", "slice": "natural_answerable"}
{"case_id": "NAT_0062", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"Moreover, our [BLANK] mechanism also evaluates other aspects of the model output quality including factuality.\"?", "gold": "self-reflection", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 23, "relevant_text": "Moreover, our self-reflection mechanism also evaluates other aspects of the model output quality including factuality.", "slice": "natural_answerable"}
{"case_id": "NAT_0063", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"Considering that retrieval is sometimes [BLANK] for some queries, conversely, responses without retrieval are even more accurate in many situations.\"?", "gold": "unnecessary", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 21, "relevant_text": "Considering that retrieval is sometimes unnecessary for some queries, conversely, responses without retrieval are even more accurate in many situations.", "slice": "natural_answerable"}
{"case_id": "NAT_0064", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"The Contriever uses a dual-encoder architecture, where the query and documents are embedded [BLANK] by a transformer encoder (Huang et al., 2013; Karpukhin et al., 2020).\"?", "gold": "independently", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 19, "relevant_text": "The Contriever uses a dual-encoder architecture, where the query and documents are embedded independently by a transformer encoder (Huang et al., 2013; Karpukhin et al., 2020).", "slice": "natural_answerable"}
{"case_id": "NAT_0065", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"Experiments on four datasets covering short- and long-form generation tasks show that CRAG can [BLANK] improve the performance of RAG-based approaches.1 1 Introduction Large language models (LLMs) have attracted increasing attention and exhibited impressive\"?", "gold": "significantly", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 3, "relevant_text": "Experiments on four datasets covering short- and long-form generation tasks show that CRAG can significantly improve the performance of RAG-based approaches.1 1 Introduction Large language models (LLMs) have attracted increasing attention and exhibited impressive", "slice": "natural_answerable"}
{"case_id": "NAT_0066", "query": "According to the paper 'recomp improving retrieval augmented lms with compression and selective augmentation', what exact term completes this statement: \"further confuse LMs with irrelevant information, degrading model [BLANK] (Mallen et al., 2022; Shi et al., 2023a).\"?", "gold": "performances", "relevant_doc_id": "2310.04408__recomp_improving_retrieval_augmented_lms_with_compression_and_selective_augmentation.txt", "relevant_chunk_id": 6, "relevant_text": "further confuse LMs with irrelevant information, degrading model performances (Mallen et al., 2022; Shi et al., 2023a).", "slice": "natural_answerable"}
{"case_id": "NAT_0067", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"In summary, our [BLANK] in this paper are three-fold: 1) This paper studies the scenarios where the retriever returns inaccurate results and, to the best of our knowledge, makes the first attempt to design corrective strategies for RAG to improve its robustness.\"?", "gold": "contributions", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 15, "relevant_text": "In summary, our contributions in this paper are three-fold: 1) This paper studies the scenarios where the retriever returns inaccurate results and, to the best of our knowledge, makes the first attempt to design corrective strategies for RAG to improve its robustness.", "slice": "natural_answerable"}
{"case_id": "NAT_0068", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"Advanced RAG Many advanced [BLANK] have been developed from the original RAG in recent years (Zhang et al., 2024; Kim et al., 2024; Wa\"?", "gold": "approaches", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 20, "relevant_text": "Advanced RAG Many advanced approaches have been developed from the original RAG in recent years (Zhang et al., 2024; Kim et al., 2024; Wa", "slice": "natural_answerable"}
{"case_id": "NAT_0069", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"This process differs from [BLANK] RAG (Figure 1 left), which 1Our code and trained models are available at https://selfrag.github.io/ .\"?", "gold": "conventional", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 8, "relevant_text": "This process differs from conventional RAG (Figure 1 left), which 1Our code and trained models are available at https://selfrag.github.io/ .", "slice": "natural_answerable"}
{"case_id": "NAT_0070", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"The retrieved documents are processed, along with the current context, by a [BLANK] model using the Fusion-in-Decoder architecture (Izacard & Grave, 2020) that generates the corresponding output.\"?", "gold": "sequence-to-sequence", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 9, "relevant_text": "The retrieved documents are processed, along with the current context, by a sequence-to-sequence model using the Fusion-in-Decoder architecture (Izacard & Grave, 2020) that generates the corresponding output.", "slice": "natural_answerable"}
{"case_id": "NAT_0071", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"(2019a) introduced a method based on hard expectation- [BLANK] to tackle noisy supervision from this setting.\"?", "gold": "maximization", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 11, "relevant_text": "(2019a) introduced a method based on hard expectation- maximization to tackle noisy supervision from this setting.", "slice": "natural_answerable"}
{"case_id": "NAT_0072", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"d as follows: the system gets a text query as input, and [BLANK] a text output .\"?", "gold": "generates", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 16, "relevant_text": "d as follows: the system gets a text query as input, and generates a text output .", "slice": "natural_answerable"}
{"case_id": "NAT_0073", "query": "According to the paper 'recomp improving retrieval augmented lms with compression and selective augmentation', what exact term completes this statement: \"er model encθwhich embeds sentence siand the input sequence xinto fixed- dimensional embeddings [BLANK].\"?", "gold": "respectively", "relevant_doc_id": "2310.04408__recomp_improving_retrieval_augmented_lms_with_compression_and_selective_augmentation.txt", "relevant_chunk_id": 20, "relevant_text": "er model encθwhich embeds sentence siand the input sequence xinto fixed- dimensional embeddings respectively.", "slice": "natural_answerable"}
{"case_id": "NAT_0074", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"Clark and Gardner (2018) proposed to use a global [BLANK] over all the span corresponding to the answer, which was later applied to BERT based models (Wang et al., 2019).\"?", "gold": "normalization", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 11, "relevant_text": "Clark and Gardner (2018) proposed to use a global normalization over all the span corresponding to the answer, which was later applied to BERT based models (Wang et al., 2019).", "slice": "natural_answerable"}
{"case_id": "NAT_0075", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"Both the retriever and the language model are based on [BLANK] transformer networks, which we describe in more detail below.\"?", "gold": "pre-trained", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 18, "relevant_text": "Both the retriever and the language model are based on pre-trained transformer networks, which we describe in more detail below.", "slice": "natural_answerable"}
{"case_id": "NAT_0076", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"GMMs assume that data points are generated from a mixture of several Gaussian [BLANK].\"?", "gold": "distributions", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 27, "relevant_text": "GMMs assume that data points are generated from a mixture of several Gaussian distributions.", "slice": "natural_answerable"}
{"case_id": "NAT_0077", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"The models which extract the answers are often based on contextualized word [BLANK] such as ELMo or BERT (Peters et al., 2018; De- vlin et al., 2019), and predict a span as answer.\"?", "gold": "representations", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 6, "relevant_text": "The models which extract the answers are often based on contextualized word representations such as ELMo or BERT (Peters et al., 2018; De- vlin et al., 2019), and predict a span as answer.", "slice": "natural_answerable"}
{"case_id": "NAT_0078", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"xact Match NaturalQuestions 5 10 25 50 100 Number of passages54565860626466 TriviaQA 5 10 25 50 100 Number of passages343638404244464850 SQuADFigure 3: Performance of [BLANK] (base) on valid sets as a function of the number of retrieved passages.\"?", "gold": "fusion-in-decoder", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 25, "relevant_text": "xact Match NaturalQuestions 5 10 25 50 100 Number of passages54565860626466 TriviaQA 5 10 25 50 100 Number of passages343638404244464850 SQuADFigure 3: Performance of Fusion-in-Decoder (base) on valid sets as a function of the number of retrieved passages.", "slice": "natural_answerable"}
{"case_id": "NAT_0079", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"GraphRAG contrasts with these approaches by generating a graph index from the source data, then applying graph-based community detection to create a thematic [BLANK] of the data.\"?", "gold": "partitioning", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 18, "relevant_text": "GraphRAG contrasts with these approaches by generating a graph index from the source data, then applying graph-based community detection to create a thematic partitioning of the data.", "slice": "natural_answerable"}
{"case_id": "NAT_0080", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"But a [BLANK] portion of the text within these retrieved documents is often non- essential for generation, which should not have been equally referred to and involved in RAG.\"?", "gold": "considerable", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 9, "relevant_text": "But a considerable portion of the text within these retrieved documents is often non- essential for generation, which should not have been equally referred to and involved in RAG.", "slice": "natural_answerable"}
{"case_id": "NAT_0081", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"rticular, we show that the [BLANK] of our method signiﬁcantly improves when the number of retrieved passages increases.\"?", "gold": "performance", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 9, "relevant_text": "rticular, we show that the performance of our method signiﬁcantly improves when the number of retrieved passages increases.", "slice": "natural_answerable"}
{"case_id": "NAT_0082", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"(2023) uses [BLANK] and snippets of passages, which improves correctness on most datasets but can sometimes be a lossy means of compression.\"?", "gold": "summarizations", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 19, "relevant_text": "(2023) uses summarizations and snippets of passages, which improves correctness on most datasets but can sometimes be a lossy means of compression.", "slice": "natural_answerable"}
{"case_id": "NAT_0083", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"For [BLANK] generation, we experiment with MS-MARCO [ 1] and Jeopardy question generation, and we ﬁnd that our models generate responses that are more factual, speciﬁc, and diverse than a BART baseline.\"?", "gold": "knowledge-intensive", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 14, "relevant_text": "For knowledge-intensive generation, we experiment with MS-MARCO [ 1] and Jeopardy question generation, and we ﬁnd that our models generate responses that are more factual, speciﬁc, and diverse than a BART baseline.", "slice": "natural_answerable"}
{"case_id": "NAT_0084", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"n improve GPT- 3 performance on open-domain question answering, we approach the problem in a more general setting, including language modeling and [BLANK] tasks.\"?", "gold": "understanding", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 20, "relevant_text": "n improve GPT- 3 performance on open-domain question answering, we approach the problem in a more general setting, including language modeling and understanding tasks.", "slice": "natural_answerable"}
{"case_id": "NAT_0085", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"Encoder Encoder Encoder Context Text Decoder-only Foundation Model Sequence [BLANK] Light-weight Encoder Who is the President of USA?\"?", "gold": "precomputable", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 20, "relevant_text": "Encoder Encoder Encoder Context Text Decoder-only Foundation Model Sequence Precomputable Light-weight Encoder Who is the President of USA?", "slice": "natural_answerable"}
{"case_id": "NAT_0086", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"lements (nodes, edges, [BLANK]) that the LLM can summarize in parallel at both indexing time and query time.\"?", "gold": "covariates", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 29, "relevant_text": "lements (nodes, edges, covariates) that the LLM can summarize in parallel at both indexing time and query time.", "slice": "natural_answerable"}
{"case_id": "NAT_0087", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"In addition, in some [BLANK] generation tasks, external knowl- edge is needed more than once, and when to retrieve should be concerned.\"?", "gold": "long-text", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 22, "relevant_text": "In addition, in some long-text generation tasks, external knowl- edge is needed more than once, and when to retrieve should be concerned.", "slice": "natural_answerable"}
{"case_id": "NAT_0088", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"In other words, we would like the [BLANK] to find documents that result in lower perplex- ity scores.\"?", "gold": "retriever", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 29, "relevant_text": "In other words, we would like the retriever to find documents that result in lower perplex- ity scores.", "slice": "natural_answerable"}
{"case_id": "NAT_0089", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"Retrieval Methods [BLANK] language models (RALMs) have seen improvements in various components: the retriever, the reader, and end-to-end system trai\"?", "gold": "retrieval-augmented", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 13, "relevant_text": "Retrieval Methods Retrieval-augmented language models (RALMs) have seen improvements in various components: the retriever, the reader, and end-to-end system trai", "slice": "natural_answerable"}
{"case_id": "NAT_0090", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"Our main contribution is the idea of using text [BLANK] to allow retrieval augmentation of context at different scales, and to show its effectiveness in experiments on collections of long doc- uments.\"?", "gold": "summarization", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 10, "relevant_text": "Our main contribution is the idea of using text summarization to allow retrieval augmentation of context at different scales, and to show its effectiveness in experiments on collections of long doc- uments.", "slice": "natural_answerable"}
{"case_id": "NAT_0091", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"By processing passages [BLANK] in the en- coder, but jointly in the decoder, this method dif- fers from Min et al.\"?", "gold": "independently", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 22, "relevant_text": "By processing passages independently in the en- coder, but jointly in the decoder, this method dif- fers from Min et al.", "slice": "natural_answerable"}
{"case_id": "NAT_0092", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"This flexibility is essen- tial because individual text segments often contain [BLANK] relevant to various topics, thereby warranting their inclusion in multiple summaries.\"?", "gold": "information", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 27, "relevant_text": "This flexibility is essen- tial because individual text segments often contain information relevant to various topics, thereby warranting their inclusion in multiple summaries.", "slice": "natural_answerable"}
{"case_id": "NAT_0093", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"t prior probability pη(z|x), is a Maximum Inner Product Search (MIPS) problem, which can be [BLANK] solved in sub-linear time [ 23].\"?", "gold": "approximately", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 22, "relevant_text": "t prior probability pη(z|x), is a Maximum Inner Product Search (MIPS) problem, which can be approximately solved in sub-linear time [ 23].", "slice": "natural_answerable"}
{"case_id": "NAT_0094", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"2 Model [BLANK] We denote the decoder model as Mdecand the encoder model as Menc.\"?", "gold": "architecture", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 17, "relevant_text": "2 Model Architecture We denote the decoder model as Mdecand the encoder model as Menc.", "slice": "natural_answerable"}
{"case_id": "NAT_0095", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"is exciting, such models do have down- sides: They cannot easily expand or revise their memory, can’t [BLANK] provide insight into their predictions, and may produce “hallucinations” [ 38].\"?", "gold": "straightforwardly", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 5, "relevant_text": "is exciting, such models do have down- sides: They cannot easily expand or revise their memory, can’t straightforwardly provide insight into their predictions, and may produce “hallucinations” [ 38].", "slice": "natural_answerable"}
{"case_id": "NAT_0096", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"We marginalize the latent documents with a top-K [BLANK], either on a per-output basis (assuming the same document is responsible for all tokens) or a per-token basis (\"?", "gold": "approximation", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 10, "relevant_text": "We marginalize the latent documents with a top-K approximation, either on a per-output basis (assuming the same document is responsible for all tokens) or a per-token basis (", "slice": "natural_answerable"}
{"case_id": "NAT_0097", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"Type Input Output Definitions Retrieve x/x, y {yes, no, continue } Decides when to retrieve with R ISREL x, d {relevant , irrelevant } dprovides useful [BLANK] to solve x.\"?", "gold": "information", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 30, "relevant_text": "Type Input Output Definitions Retrieve x/x, y {yes, no, continue } Decides when to retrieve with R ISREL x, d {relevant , irrelevant } dprovides useful information to solve x.", "slice": "natural_answerable"}
{"case_id": "NAT_0098", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"Our RAG models achieve [BLANK] results on open Natural Questions [ 29], WebQuestions [ 3] and CuratedTrec [ 2] and strongly outperform recent approaches that use specialised pre-training objectives on TriviaQA [ 24].\"?", "gold": "state-of-the-art", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 13, "relevant_text": "Our RAG models achieve state-of-the-art results on open Natural Questions [ 29], WebQuestions [ 3] and CuratedTrec [ 2] and strongly outperform recent approaches that use specialised pre-training objectives on TriviaQA [ 24].", "slice": "natural_answerable"}
{"case_id": "NAT_0099", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"GraphRAG leverages summaries over large sections of the data source as a form of ”[BLANK]” (described in Cheng et al.\"?", "gold": "self-memory", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 16, "relevant_text": "GraphRAG leverages summaries over large sections of the data source as a form of ”self-memory” (described in Cheng et al.", "slice": "natural_answerable"}
{"case_id": "NAT_0100", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"They are able to learn new tasks with very few examples or even from [BLANK] alone.\"?", "gold": "instructions", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 3, "relevant_text": "They are able to learn new tasks with very few examples or even from instructions alone.", "slice": "natural_answerable"}
{"case_id": "NAT_0101", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"1 [BLANK] Recently, several works have shown that factual information can be extracted from large scale language models trained on vast quantities of data (Radford et al., 2019; Petroni et al., 2019; Jiang et al., 2019; Talmor et al., 2019).\"?", "gold": "introduction", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 2, "relevant_text": "1 Introduction Recently, several works have shown that factual information can be extracted from large scale language models trained on vast quantities of data (Radford et al., 2019; Petroni et al., 2019; Jiang et al., 2019; Talmor et al., 2019).", "slice": "natural_answerable"}
{"case_id": "NAT_0102", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"(y) Question Answering: Answer [BLANK] pη (Non-Parametric) z 4 z3 z2 z 1d(z) Jeopardy Question Generation: Answer QueryFigure 1: Overview of our approach.\"?", "gold": "generationretriever", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 7, "relevant_text": "(y) Question Answering: Answer GenerationRetriever pη (Non-Parametric) z 4 z3 z2 z 1d(z) Jeopardy Question Generation: Answer QueryFigure 1: Overview of our approach.", "slice": "natural_answerable"}
{"case_id": "NAT_0103", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"xamples, [BLANK] a 540B parameters model by 3% despite having 50x fewer parameters.\"?", "gold": "outperforming", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 3, "relevant_text": "xamples, outperforming a 540B parameters model by 3% despite having 50x fewer parameters.", "slice": "natural_answerable"}
{"case_id": "NAT_0104", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"A more recent work (Luo et al., 2023) [BLANK] an LM with a fixed number 2 Preprint.\"?", "gold": "instruction-tunes", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 19, "relevant_text": "A more recent work (Luo et al., 2023) instruction-tunes an LM with a fixed number 2 Preprint.", "slice": "natural_answerable"}
{"case_id": "NAT_0105", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"In this framework, the input to models is augmented by [BLANK] relevant documents that are retrieved from an external knowledge corpus (Guu et al., 2020).\"?", "gold": "prepending", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 7, "relevant_text": "In this framework, the input to models is augmented by prepending relevant documents that are retrieved from an external knowledge corpus (Guu et al., 2020).", "slice": "natural_answerable"}
{"case_id": "NAT_0106", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"These models are typically trained on very large datasets and store a [BLANK] amount of world or domain knowledge implicitly in their parameters.\"?", "gold": "substantial", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 2, "relevant_text": "These models are typically trained on very large datasets and store a substantial amount of world or domain knowledge implicitly in their parameters.", "slice": "natural_answerable"}
{"case_id": "NAT_0107", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"Empirically, as shown in figure 2, with a context length of16384(mid-to-long context),REFRAG with k= 16achieves16 .53×TTFT [BLANK] with cache and8 .59×without cache1, both surpassing CEPE (\"?", "gold": "acceleration", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 24, "relevant_text": "Empirically, as shown in figure 2, with a context length of16384(mid-to-long context),REFRAG with k= 16achieves16 .53×TTFT acceleration with cache and8 .59×without cache1, both surpassing CEPE (", "slice": "natural_answerable"}
{"case_id": "NAT_0108", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"We refer to this decoding [BLANK] as “Thorough Decoding.” For longer output seq\"?", "gold": "procedure", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 27, "relevant_text": "We refer to this decoding procedure as “Thorough Decoding.” For longer output seq", "slice": "natural_answerable"}
{"case_id": "NAT_0109", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"This al- lows to scale to large numbers of [BLANK], and to beneﬁt from this large amount of evidence.\"?", "gold": "documents", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 16, "relevant_text": "This al- lows to scale to large numbers of documents, and to beneﬁt from this large amount of evidence.", "slice": "natural_answerable"}
{"case_id": "NAT_0110", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"How- ever, the increasing scale and black-box nature of large language models makes this approach [BLANK].\"?", "gold": "infeasible", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 14, "relevant_text": "How- ever, the increasing scale and black-box nature of large language models makes this approach infeasible.", "slice": "natural_answerable"}
{"case_id": "NAT_0111", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"generated texts such as “fluency” (Wang et al., 2023a) Some of these criteria are generic to vector RAG systems and not relevant to global sensemaking, such as “context relevance”, “[BLANK]”, and “answer relevance” (RAGAS, Es et al\"?", "gold": "faithfulness", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 29, "relevant_text": "generated texts such as “fluency” (Wang et al., 2023a) Some of these criteria are generic to vector RAG systems and not relevant to global sensemaking, such as “context relevance”, “faithfulness”, and “answer relevance” (RAGAS, Es et al", "slice": "natural_answerable"}
{"case_id": "NAT_0112", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"In this work, we de- sign criteria for evaluating [BLANK] answers to global sensemaking questions and evaluate our results using the comparative approach.\"?", "gold": "rag-generated", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 30, "relevant_text": "In this work, we de- sign criteria for evaluating RAG-generated answers to global sensemaking questions and evaluate our results using the comparative approach.", "slice": "natural_answerable"}
{"case_id": "NAT_0113", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"We use a training objective which prefers [BLANK] documents that improve language model perplexity, while treating the LM as a frozen, black-box scoring function.\"?", "gold": "retrieving", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 9, "relevant_text": "We use a training objective which prefers retrieving documents that improve language model perplexity, while treating the LM as a frozen, black-box scoring function.", "slice": "natural_answerable"}
{"case_id": "NAT_0114", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"This [BLANK] is implemented to broaden the spectrum of retrieved information, harnessing the expansive and dynamic nature of the web to complement and enrich the initially obtained documents.\"?", "gold": "augmentation", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 12, "relevant_text": "This augmentation is implemented to broaden the spectrum of retrieved information, harnessing the expansive and dynamic nature of the web to complement and enrich the initially obtained documents.", "slice": "natural_answerable"}
{"case_id": "NAT_0115", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"Together, these community summaries provide global [BLANK] and insights over the corpus.\"?", "gold": "descriptions", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 10, "relevant_text": "Together, these community summaries provide global descriptions and insights over the corpus.", "slice": "natural_answerable"}
{"case_id": "NAT_0116", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"As shown in Figure 2, given an input context, REPLUG first [BLANK] a small set of relevant documents from an external corpus using a retriever (§3.1).\"?", "gold": "retrieves", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 22, "relevant_text": "As shown in Figure 2, given an input context, REPLUG first retrieves a small set of relevant documents from an external corpus using a retriever (§3.1).", "slice": "natural_answerable"}
{"case_id": "NAT_0117", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"[BLANK] Large language models (LLMs) such as GPT-3 (Brown et al., 2020a) and Codex (Chen et al., 2021a), have demonstrated impressive performance on a wide range of language tasks.\"?", "gold": "introduction", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 2, "relevant_text": "Introduction Large language models (LLMs) such as GPT-3 (Brown et al., 2020a) and Codex (Chen et al., 2021a), have demonstrated impressive performance on a wide range of language tasks.", "slice": "natural_answerable"}
{"case_id": "NAT_0118", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"As shown in Figure 1, our system, RAPTOR, clusters chunks of text, generates text summaries of those clusters, and then repeats, [BLANK] a tree from the bottom up.\"?", "gold": "generating", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 8, "relevant_text": "As shown in Figure 1, our system, RAPTOR, clusters chunks of text, generates text summaries of those clusters, and then repeats, generating a tree from the bottom up.", "slice": "natural_answerable"}
{"case_id": "NAT_0119", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"[BLANK] methods were pro- posed to tackle the setting where no gold spans are given to the system, but only the correct answer.\"?", "gold": "different", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 11, "relevant_text": "Different methods were pro- posed to tackle the setting where no gold spans are given to the system, but only the correct answer.", "slice": "natural_answerable"}
{"case_id": "NAT_0120", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"For clarity, we focus on a single turn of [BLANK] and retrieval in this section.\"?", "gold": "question", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 17, "relevant_text": "For clarity, we focus on a single turn of question and retrieval in this section.", "slice": "natural_answerable"}
{"case_id": "NAT_0121", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"The challenge, however, arises when the volume of data requires a RAG approach, since vector RAG approaches are unable to support [BLANK] over an entire corpus.\"?", "gold": "sensemaking", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 8, "relevant_text": "The challenge, however, arises when the volume of data requires a RAG approach, since vector RAG approaches are unable to support sensemaking over an entire corpus.", "slice": "natural_answerable"}
{"case_id": "NAT_0122", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"Step 3: Critique outputs and select best [BLANK] in a 16th-century novel Las Sergas de Esplandián.\"?", "gold": "segmentorigins", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 11, "relevant_text": "Step 3: Critique outputs and select best segmentorigins in a 16th-century novel Las Sergas de Esplandián.", "slice": "natural_answerable"}
{"case_id": "NAT_0123", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"Given a question, each community summary is used to generate a partial response, before all partial responses are again [BLANK] in a final response to the user.\"?", "gold": "summarized", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 3, "relevant_text": "Given a question, each community summary is used to generate a partial response, before all partial responses are again summarized in a final response to the user.", "slice": "natural_answerable"}
{"case_id": "NAT_0124", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"In the canonical RAG setup, the system has access to a large external corpus of text records and retrieves a subset of records that are [BLANK] relevant to the query and collectively small enough to fit into the context window of the LLM.\"?", "gold": "individually", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 5, "relevant_text": "In the canonical RAG setup, the system has access to a large external corpus of text records and retrieves a subset of records that are individually relevant to the query and collectively small enough to fit into the context window of the LLM.", "slice": "natural_answerable"}
{"case_id": "NAT_0125", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"In this work we address this gap, and present Atlas, a [BLANK] language model capable of strong few-shot learning, despite having lower parameter counts\"?", "gold": "retrieval-augmented", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 8, "relevant_text": "In this work we address this gap, and present Atlas, a retrieval-augmented language model capable of strong few-shot learning, despite having lower parameter counts", "slice": "natural_answerable"}
{"case_id": "NAT_0126", "query": "According to the paper 'recomp improving retrieval augmented lms with compression and selective augmentation', what exact term completes this statement: \"We evaluate our approach on language modeling task and open domain question [BLANK] task.\"?", "gold": "answering", "relevant_doc_id": "2310.04408__recomp_improving_retrieval_augmented_lms_with_compression_and_selective_augmentation.txt", "relevant_chunk_id": 3, "relevant_text": "We evaluate our approach on language modeling task and open domain question answering task.", "slice": "natural_answerable"}
{"case_id": "NAT_0127", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"Earlier studies adopt either sparse or dense retrievers at the front end of a pre- trained language model that [BLANK] in response generation.\"?", "gold": "specializes", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 19, "relevant_text": "Earlier studies adopt either sparse or dense retrievers at the front end of a pre- trained language model that specializes in response generation.", "slice": "natural_answerable"}
{"case_id": "NAT_0128", "query": "According to the paper 'recomp improving retrieval augmented lms with compression and selective augmentation', what exact term completes this statement: \"As this approach is extractive, we assume the faithfulness criteria is mostly satisfied.3 Abstractive Compressor We train an [BLANK] model encdec θto serve as\"?", "gold": "encoder-decoder", "relevant_doc_id": "2310.04408__recomp_improving_retrieval_augmented_lms_with_compression_and_selective_augmentation.txt", "relevant_chunk_id": 20, "relevant_text": "As this approach is extractive, we assume the faithfulness criteria is mostly satisfied.3 Abstractive Compressor We train an encoder-decoder model encdec θto serve as", "slice": "natural_answerable"}
{"case_id": "NAT_0129", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"[BLANK] Models Augmenting language models with relevant information retrieved from various knowledge stores has shown to be effective in improving performance on various NLP tasks, including language mod- eling (Min et al., 2022;\"?", "gold": "retrieval-augmented", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 15, "relevant_text": "Retrieval-augmented Models Augmenting language models with relevant information retrieved from various knowledge stores has shown to be effective in improving performance on various NLP tasks, including language mod- eling (Min et al., 2022;", "slice": "natural_answerable"}
{"case_id": "NAT_0130", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"In the following, we formally introduce both models and then describe the pηandpθ[BLANK], as well as the training and\"?", "gold": "components", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 17, "relevant_text": "In the following, we formally introduce both models and then describe the pηandpθcomponents, as well as the training and", "slice": "natural_answerable"}
{"case_id": "NAT_0131", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"These projected chunk [BLANK] are then fed to the decoder model along with the token embeddings for the question to generate the answer y∼ M dec({e1, .\"?", "gold": "embeddings", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 19, "relevant_text": "These projected chunk embeddings are then fed to the decoder model along with the token embeddings for the question to generate the answer y∼ M dec({e1, .", "slice": "natural_answerable"}
{"case_id": "NAT_0132", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"Despite this, the methods above usually ignore a [BLANK], what if the retrieval goes wrong?\"?", "gold": "question", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 20, "relevant_text": "Despite this, the methods above usually ignore a question, what if the retrieval goes wrong?", "slice": "natural_answerable"}
{"case_id": "NAT_0133", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"Experiments show that SELF- RAG(7B and 13B parameters) significantly outperforms state-of-the-art LLMs and [BLANK] models on a diverse set of tasks.\"?", "gold": "retrieval-augmented", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 3, "relevant_text": "Experiments show that SELF- RAG(7B and 13B parameters) significantly outperforms state-of-the-art LLMs and retrieval-augmented models on a diverse set of tasks.", "slice": "natural_answerable"}
{"case_id": "NAT_0134", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"Without relying on external knowledge, this method obtained compet- itive results on several [BLANK].\"?", "gold": "benchmarks", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 3, "relevant_text": "Without relying on external knowledge, this method obtained compet- itive results on several benchmarks.", "slice": "natural_answerable"}
{"case_id": "NAT_0135", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"This approach scales well with the number of retrieved passages, as the [BLANK] keeps improving when retrieving up to one hundred passages.\"?", "gold": "performance", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 5, "relevant_text": "This approach scales well with the number of retrieved passages, as the performance keeps improving when retrieving up to one hundred passages.", "slice": "natural_answerable"}
{"case_id": "NAT_0136", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"A [BLANK] retrieval evaluator is designed to assess the overall quality of retrieved documents for a query.\"?", "gold": "lightweight", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 10, "relevant_text": "A lightweight retrieval evaluator is designed to assess the overall quality of retrieved documents for a query.", "slice": "natural_answerable"}
{"case_id": "NAT_0137", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"Background and Related Work Black-box Language Models Large language models (i.e., >100B), such as GPT-3 (Brown et al., 2020a), Codex (Chen et al., 2021a), and Yuan 1.0 (Wu et al., 2021), are not [BLANK] due to commercial consi\"?", "gold": "open-sourced", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 12, "relevant_text": "Background and Related Work Black-box Language Models Large language models (i.e., >100B), such as GPT-3 (Brown et al., 2020a), Codex (Chen et al., 2021a), and Yuan 1.0 (Wu et al., 2021), are not open-sourced due to commercial consi", "slice": "natural_answerable"}
{"case_id": "NAT_0138", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"Therefore, com- pared with the method of prepending all the retrieved docu- REPLUG: [BLANK]\"?", "gold": "retrieval-a", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 27, "relevant_text": "Therefore, com- pared with the method of prepending all the retrieved docu- REPLUG: Retrieval-A", "slice": "natural_answerable"}
{"case_id": "NAT_0139", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"As a result, LLM inference throughput degrades with larger contexts, limiting their [BLANK] in scenarios demanding high throughput and low latency, such as web-scale discovery.\"?", "gold": "applicability", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 8, "relevant_text": "As a result, LLM inference throughput degrades with larger contexts, limiting their applicability in scenarios demanding high throughput and low latency, such as web-scale discovery.", "slice": "natural_answerable"}
{"case_id": "NAT_0140", "query": "According to the paper 'recomp improving retrieval augmented lms with compression and selective augmentation', what exact term completes this statement: \"odels in the output should be faithful to the original input, yet the main goal is [BLANK].\"?", "gold": "different", "relevant_doc_id": "2310.04408__recomp_improving_retrieval_augmented_lms_with_compression_and_selective_augmentation.txt", "relevant_chunk_id": 23, "relevant_text": "odels in the output should be faithful to the original input, yet the main goal is different.", "slice": "natural_answerable"}
{"case_id": "NAT_0141", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"The ﬁrst loss that we consider is based on the attention scores of the language model, and is heavily [BLANK] by Izacard & Grave (2021).\"?", "gold": "inspired", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 25, "relevant_text": "The ﬁrst loss that we consider is based on the attention scores of the language model, and is heavily inspired by Izacard & Grave (2021).", "slice": "natural_answerable"}
{"case_id": "NAT_0142", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"1 [BLANK] Large language models (LLMs) are impressive few-shot learners (Brown et al., 2020; Rae et al., 2021; Hoﬀmann et al., 2022; Chowdhery et al., 2022).\"?", "gold": "introduction", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 3, "relevant_text": "1 Introduction Large language models (LLMs) are impressive few-shot learners (Brown et al., 2020; Rae et al., 2021; Hoﬀmann et al., 2022; Chowdhery et al., 2022).", "slice": "natural_answerable"}
{"case_id": "NAT_0143", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"Controlled experiments show that retrieval with recursive summaries offers [BLANK] improv\"?", "gold": "significant", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 1, "relevant_text": "Controlled experiments show that retrieval with recursive summaries offers significant improv", "slice": "natural_answerable"}
{"case_id": "NAT_0144", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"(2023) fine-tune both the retriever and LM on [BLANK] datasets in two step\"?", "gold": "instruction-tuning", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 21, "relevant_text": "(2023) fine-tune both the retriever and LM on instruction-tuning datasets in two step", "slice": "natural_answerable"}
{"case_id": "NAT_0145", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"This is exactly the focus of this paper to improve the [BLANK] of generation.\"?", "gold": "robustness", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 26, "relevant_text": "This is exactly the focus of this paper to improve the robustness of generation.", "slice": "natural_answerable"}
{"case_id": "NAT_0146", "query": "According to the paper 'recomp improving retrieval augmented lms with compression and selective augmentation', what exact term completes this statement: \"Training a [BLANK] for QA task works similarly, but scoring will evaluate whether the LM will generate t\"?", "gold": "compressor", "relevant_doc_id": "2310.04408__recomp_improving_retrieval_augmented_lms_with_compression_and_selective_augmentation.txt", "relevant_chunk_id": 29, "relevant_text": "Training a compressor for QA task works similarly, but scoring will evaluate whether the LM will generate t", "slice": "natural_answerable"}
{"case_id": "NAT_0147", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"In particular, GraphRAG is similar to other approaches that use [BLANK] indexing to create summaries (similar to Kim et al.\"?", "gold": "hierarchical", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 17, "relevant_text": "In particular, GraphRAG is similar to other approaches that use hierarchical indexing to create summaries (similar to Kim et al.", "slice": "natural_answerable"}
{"case_id": "NAT_0148", "query": "According to the paper 'recomp improving retrieval augmented lms with compression and selective augmentation', what exact term completes this statement: \"3 L EARNING THE COMPRESSORS Our compressor resembles text [BLANK] models in the output should be faithful to the original input, ye\"?", "gold": "summarization", "relevant_doc_id": "2310.04408__recomp_improving_retrieval_augmented_lms_with_compression_and_selective_augmentation.txt", "relevant_chunk_id": 22, "relevant_text": "3 L EARNING THE COMPRESSORS Our compressor resembles text summarization models in the output should be faithful to the original input, ye", "slice": "natural_answerable"}
{"case_id": "NAT_0149", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"Here, this loss is only used to optimize the [BLANK] of the retriever, and not the language model.\"?", "gold": "parameters", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 29, "relevant_text": "Here, this loss is only used to optimize the parameters of the retriever, and not the language model.", "slice": "natural_answerable"}
{"case_id": "NAT_0150", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"To train the retriever and generator [BLANK], we treat the retrieved document as a latent va\"?", "gold": "end-to-end", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 16, "relevant_text": "To train the retriever and generator end-to-end, we treat the retrieved document as a latent va", "slice": "natural_answerable"}
{"case_id": "NAT_0151", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"These datasets were gen- erated in a way that answers do not [BLANK] to spans in support documents, t\"?", "gold": "correspond", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 14, "relevant_text": "These datasets were gen- erated in a way that answers do not correspond to spans in support documents, t", "slice": "natural_answerable"}
{"case_id": "NAT_0152", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"provide rigorous validation [BLANK] diverse long-context tasks, including RAG, multi-turn conversations, and long document summarization, spanning a wide range of datasets.\"?", "gold": "ofrefragacross", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 4, "relevant_text": "provide rigorous validation ofREFRAGacross diverse long-context tasks, including RAG, multi-turn conversations, and long document summarization, spanning a wide range of datasets.", "slice": "natural_answerable"}
{"case_id": "NAT_0153", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"1 I NTRODUCTION Large Language Models (LLMs) have emerged as [BLANK] tools showing impressive perfor- mance on m\"?", "gold": "transformative", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 2, "relevant_text": "1 I NTRODUCTION Large Language Models (LLMs) have emerged as transformative tools showing impressive perfor- mance on m", "slice": "natural_answerable"}
{"case_id": "NAT_0154", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"In BM25, passages are [BLANK] as bag of words, and the ranking function is based on term and inverse doc- ument frequencies.\"?", "gold": "represented", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 19, "relevant_text": "In BM25, passages are represented as bag of words, and the ranking function is based on term and inverse doc- ument frequencies.", "slice": "natural_answerable"}
{"case_id": "NAT_0155", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"[BLANK] language models (Khandelwal et al., 2020; Borgeaud et al., 2022; Izacard et al., 2022b; Yasunaga et al., 2022), in con- trast, can retrieve knowledge from an external datastore when needed, potentially reducing hallucination and increas- ing coverage.\"?", "gold": "retrieval-augmented", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 3, "relevant_text": "Retrieval-augmented language models (Khandelwal et al., 2020; Borgeaud et al., 2022; Izacard et al., 2022b; Yasunaga et al., 2022), in con- trast, can retrieve knowledge from an external datastore when needed, potentially reducing hallucination and increas- ing coverage.", "slice": "natural_answerable"}
{"case_id": "NAT_0156", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"During CPT, we input the first stokens x1:sinto the encoder and use its output to assist the decoder in [BLANK] the next otokens xs+1:s+o.\"?", "gold": "predicting", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 27, "relevant_text": "During CPT, we input the first stokens x1:sinto the encoder and use its output to assist the decoder in predicting the next otokens xs+1:s+o.", "slice": "natural_answerable"}
{"case_id": "NAT_0157", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"Here, we bring hybrid parametric and [BLANK] memory to the “workhorse of NLP,” i.e.\"?", "gold": "non-parametric", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 8, "relevant_text": "Here, we bring hybrid parametric and non-parametric memory to the “workhorse of NLP,” i.e.", "slice": "natural_answerable"}
{"case_id": "NAT_0158", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"[BLANK] Generation (RAG) augments the input space of LMs with retrieved text passages (Guu et al., 2020; Lewis et al., 2020), lea\"?", "gold": "retrieval-augmented", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 18, "relevant_text": "Retrieval-Augmented Generation (RAG) augments the input space of LMs with retrieved text passages (Guu et al., 2020; Lewis et al., 2020), lea", "slice": "natural_answerable"}
{"case_id": "NAT_0159", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"While Toolformer (Schick et al., 2023) is [BLANK] for calling APIs such as Wikipedia.\"?", "gold": "pre-trained", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 22, "relevant_text": "While Toolformer (Schick et al., 2023) is pre-trained for calling APIs such as Wikipedia.", "slice": "natural_answerable"}
{"case_id": "NAT_0160", "query": "According to the paper 'recomp improving retrieval augmented lms with compression and selective augmentation', what exact term completes this statement: \"3 Score (M,yi,[sj;xi]) = log pM(y|[sj;xi]), log [BLANK] assigned to target output accord\"?", "gold": "likelihood", "relevant_doc_id": "2310.04408__recomp_improving_retrieval_augmented_lms_with_compression_and_selective_augmentation.txt", "relevant_chunk_id": 28, "relevant_text": "3 Score (M,yi,[sj;xi]) = log pM(y|[sj;xi]), log likelihood assigned to target output accord", "slice": "natural_answerable"}
{"case_id": "NAT_0161", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"[BLANK], GraphRAG recursively creates increasingly global summaries by using the LLM to create summaries spanni\"?", "gold": "specifically", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 21, "relevant_text": "Specifically, GraphRAG recursively creates increasingly global summaries by using the LLM to create summaries spanni", "slice": "natural_answerable"}
{"case_id": "NAT_0162", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"[BLANK] Generation (RAG)Ours: Self-reﬂective Retrieval-Augmented Genera\"?", "gold": "retrieval-augmented", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 9, "relevant_text": "Retrieval-Augmented Generation (RAG)Ours: Self-reﬂective Retrieval-Augmented Genera", "slice": "natural_answerable"}
{"case_id": "NAT_0163", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"•Thorough downstream experiments in few-shot settings, demonstrating [BLANK] results on few-shot NaturalQuestions (+2.8%), TriviaQA (+3.3%), FEVER (+5.1%), and results on par or stronger than models with 15 ×more parameters on MMLU.\"?", "gold": "state-of-the-art", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 13, "relevant_text": "•Thorough downstream experiments in few-shot settings, demonstrating state-of-the-art results on few-shot NaturalQuestions (+2.8%), TriviaQA (+3.3%), FEVER (+5.1%), and results on par or stronger than models with 15 ×more parameters on MMLU.", "slice": "natural_answerable"}
{"case_id": "NAT_0164", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"Internal [BLANK] of such models are not exposed and fine-tuning is not supported.\"?", "gold": "representations", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 6, "relevant_text": "Internal representations of such models are not exposed and fine-tuning is not supported.", "slice": "natural_answerable"}
{"case_id": "NAT_0165", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"Technically, it treats the retrieved document as a single latent variable that is marginalized to get the seq2seq probability p(y|x)via a top-K [BLANK].\"?", "gold": "approximation", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 18, "relevant_text": "Technically, it treats the retrieved document as a single latent variable that is marginalized to get the seq2seq probability p(y|x)via a top-K approximation.", "slice": "natural_answerable"}
{"case_id": "NAT_0166", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"For a class of global sensemaking questions over datasets in the 1 million token range, we show that GraphRAG leads to substantial [BLANK] over a conventional RAG baseline for\"?", "gold": "improvements", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 3, "relevant_text": "For a class of global sensemaking questions over datasets in the 1 million token range, we show that GraphRAG leads to substantial improvements over a conventional RAG baseline for", "slice": "natural_answerable"}
{"case_id": "NAT_0167", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"Though our work also studies [BLANK] critique on retrieval and generation, we train our target LM on task examples augmented with reflection tokens from a critic model offline, with a far lower training cost compared to RLHF.\"?", "gold": "fine-grained", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 25, "relevant_text": "Though our work also studies fine-grained critique on retrieval and generation, we train our target LM on task examples augmented with reflection tokens from a critic model offline, with a far lower training cost compared to RLHF.", "slice": "natural_answerable"}
{"case_id": "NAT_0168", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"This refinement operation involves knowledge decom- position, filter, and [BLANK] (Section 4.4).\"?", "gold": "recomposition", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 27, "relevant_text": "This refinement operation involves knowledge decom- position, filter, and recomposition (Section 4.4).", "slice": "natural_answerable"}
{"case_id": "NAT_0169", "query": "According to the paper 'recomp improving retrieval augmented lms with compression and selective augmentation', what exact term completes this statement: \"We propose compressors: (1) Extractive compressor which selects relevant sentences from retrieved document set; (2) Abstractive compressor which generates a summary [BLANK] information from multiple retrieved documents.\"?", "gold": "synthesizing", "relevant_doc_id": "2310.04408__recomp_improving_retrieval_augmented_lms_with_compression_and_selective_augmentation.txt", "relevant_chunk_id": 11, "relevant_text": "We propose compressors: (1) Extractive compressor which selects relevant sentences from retrieved document set; (2) Abstractive compressor which generates a summary synthesizing information from multiple retrieved documents.", "slice": "natural_answerable"}
{"case_id": "NAT_0170", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"As shown inarXiv:2301.12652v4 [cs.CL] 24 May 2023 REPLUG: [BLANK] Black-Box Language Models Figure 1, REPLUG is extremely flexible\"?", "gold": "retrieval-augmented", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 7, "relevant_text": "As shown inarXiv:2301.12652v4 [cs.CL] 24 May 2023 REPLUG: Retrieval-Augmented Black-Box Language Models Figure 1, REPLUG is extremely flexible", "slice": "natural_answerable"}
{"case_id": "NAT_0171", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"Ms) have attracted increasing attention and exhibited impressive abili- ties to understand [BLANK] and generate fluent language texts (Brown et al., 2020; Ouyang et al., 2022; Touvron et al., 2023a).\"?", "gold": "instructions", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 4, "relevant_text": "Ms) have attracted increasing attention and exhibited impressive abili- ties to understand instructions and generate fluent language texts (Brown et al., 2020; Ouyang et al., 2022; Touvron et al., 2023a).", "slice": "natural_answerable"}
{"case_id": "NAT_0172", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"Furthermore, current methods mostly treat complete documents as reference knowledge both during retrieval and [BLANK].\"?", "gold": "utilization", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 9, "relevant_text": "Furthermore, current methods mostly treat complete documents as reference knowledge both during retrieval and utilization.", "slice": "natural_answerable"}
{"case_id": "NAT_0173", "query": "According to the paper 'recomp improving retrieval augmented lms with compression and selective augmentation', what exact term completes this statement: \"Early US models include X, S and PRO-4X, with a choice of 6-speed manual or 5-speed automatic [BLANK], a choice of [...] moved from Smyrna, Tennessee, to Nissan's facility in Canton, Mississippi.\"?", "gold": "transmissions", "relevant_doc_id": "2310.04408__recomp_improving_retrieval_augmented_lms_with_compression_and_selective_augmentation.txt", "relevant_chunk_id": 9, "relevant_text": "Early US models include X, S and PRO-4X, with a choice of 6-speed manual or 5-speed automatic transmissions, a choice of [...] moved from Smyrna, Tennessee, to Nissan's facility in Canton, Mississippi.", "slice": "natural_answerable"}
{"case_id": "NAT_0174", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"uestion answering systems (Chen et al., 2017; Yu et al., 2018), is to index large quantities of text, after splitting it into chunks (paragraphs), in a separate [BLANK] retrieval system.\"?", "gold": "information", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 5, "relevant_text": "uestion answering systems (Chen et al., 2017; Yu et al., 2018), is to index large quantities of text, after splitting it into chunks (paragraphs), in a separate information retrieval system.", "slice": "natural_answerable"}
{"case_id": "NAT_0175", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"The relevance score is quantified into a total of three confidence degrees and then triggered the [BLANK] actions: { Correct ,Incorrect , Ambiguous } (Section 4.3).\"?", "gold": "corresponding", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 27, "relevant_text": "The relevance score is quantified into a total of three confidence degrees and then triggered the corresponding actions: { Correct ,Incorrect , Ambiguous } (Section 4.3).", "slice": "natural_answerable"}
{"case_id": "NAT_0176", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"Born in Maida Vale, London…Where was Alan Turing born?[BLANK]2seq modelMaida Vale, LondonFigure 1: A simple approach to open domain question answering.\"?", "gold": "generativeseq", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 4, "relevant_text": "Born in Maida Vale, London…Where was Alan Turing born?Generativeseq2seq modelMaida Vale, LondonFigure 1: A simple approach to open domain question answering.", "slice": "natural_answerable"}
{"case_id": "NAT_0177", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"Retrieval methods have [BLANK] from traditional term-based techniques like TF-IDF (Sp¨arck Jones, 1972) and BM25 (Robertson et al., 1995; Roberts et al., 2020) to deep learning–based strategies (Karpukhin et al., 2020; Khattab & Zaharia, 2020; Sachan et al., 2023).\"?", "gold": "transitioned", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 14, "relevant_text": "Retrieval methods have transitioned from traditional term-based techniques like TF-IDF (Sp¨arck Jones, 1972) and BM25 (Robertson et al., 1995; Roberts et al., 2020) to deep learning–based strategies (Karpukhin et al., 2020; Khattab & Zaharia, 2020; Sachan et al., 2023).", "slice": "natural_answerable"}
{"case_id": "NAT_0178", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"While being a [BLANK] problem in natural lan- guage processing (V oorhees et al., 199\"?", "gold": "longstanding", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 9, "relevant_text": "While being a longstanding problem in natural lan- guage processing (V oorhees et al., 199", "slice": "natural_answerable"}
{"case_id": "NAT_0179", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"This style of retrieval can be added to both encoder- decoder (Yu, 2022; Izacard et al., 2022b) and [BLANK] models (Khandelwal et al., 2020; Borgeaud et al., 2022; Shi et al., 2022; Rubin et al., 2022).\"?", "gold": "decoder-only", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 17, "relevant_text": "This style of retrieval can be added to both encoder- decoder (Yu, 2022; Izacard et al., 2022b) and decoder-only models (Khandelwal et al., 2020; Borgeaud et al., 2022; Shi et al., 2022; Rubin et al., 2022).", "slice": "natural_answerable"}
{"case_id": "NAT_0180", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"(2023) highlights a potential [BLANK]: contiguous seg- mentation might not capture the complete semantic depth of the text.\"?", "gold": "shortcoming", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 18, "relevant_text": "(2023) highlights a potential shortcoming: contiguous seg- mentation might not capture the complete semantic depth of the text.", "slice": "natural_answerable"}
{"case_id": "NAT_0181", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"for long-form generations relative to these models.1 1 I NTRODUCTION [BLANK] LLMs continue to struggle with factual errors (Mallen et al., 2023; Min et al., 2023) despite their increased model and data scale (Ouyang et al., 2022).\"?", "gold": "state-of-the-art", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 4, "relevant_text": "for long-form generations relative to these models.1 1 I NTRODUCTION State-of-the-art LLMs continue to struggle with factual errors (Mallen et al., 2023; Min et al., 2023) despite their increased model and data scale (Ouyang et al., 2022).", "slice": "natural_answerable"}
{"case_id": "NAT_0182", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"cted communities, with summaries at higher levels of the hierarchy recursively [BLANK] lower-level summaries.\"?", "gold": "incorporating", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 10, "relevant_text": "cted communities, with summaries at higher levels of the hierarchy recursively incorporating lower-level summaries.", "slice": "natural_answerable"}
{"case_id": "NAT_0183", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"To this end, we propose REFRAG, an efficient decoding framework that compresses, senses, and expands to improve latency in RAG [BLANK].\"?", "gold": "applications", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 3, "relevant_text": "To this end, we propose REFRAG, an efficient decoding framework that compresses, senses, and expands to improve latency in RAG applications.", "slice": "natural_answerable"}
{"case_id": "NAT_0184", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"The objective is to align any encoder–decoder combination so that the generations produced [BLANK] contextclosely resemble those generated by the original decoder with access to the full context.\"?", "gold": "withcompressed", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 28, "relevant_text": "The objective is to align any encoder–decoder combination so that the generations produced withcompressed contextclosely resemble those generated by the original decoder with access to the full context.", "slice": "natural_answerable"}
{"case_id": "NAT_0185", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"For language generation tasks, we ﬁnd that RAG models generate more speciﬁc, diverse and factual language than a [BLANK] parametric-only seq2seq baseline.\"?", "gold": "state-of-the-art", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 4, "relevant_text": "For language generation tasks, we ﬁnd that RAG models generate more speciﬁc, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.", "slice": "natural_answerable"}
{"case_id": "NAT_0186", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"On the other hand, pro- cessing passages jointly in the decoder allows to better [BLANK] evidence from multiple passages.\"?", "gold": "aggregate", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 23, "relevant_text": "On the other hand, pro- cessing passages jointly in the decoder allows to better aggregate evidence from multiple passages.", "slice": "natural_answerable"}
{"case_id": "NAT_0187", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"We endow pre-trained, parametric-memory generation models with a non-parametric memory through a general-purpose ﬁne-tuning approach which we refer to as [BLANK] generation (RAG).\"?", "gold": "retrieval-augmented", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 9, "relevant_text": "We endow pre-trained, parametric-memory generation models with a non-parametric memory through a general-purpose ﬁne-tuning approach which we refer to as retrieval-augmented generation (RAG).", "slice": "natural_answerable"}
{"case_id": "NAT_0188", "query": "According to the paper 'self rag learning to retrieve generate and critique through self reflection', what exact term completes this statement: \"If so, it outputs a retrieval token that calls a [BLANK] model on demand (Step 1).\"?", "gold": "retriever", "relevant_doc_id": "2310.11511__self_rag_learning_to_retrieve_generate_and_critique_through_self_reflection.txt", "relevant_chunk_id": 7, "relevant_text": "If so, it outputs a retrieval token that calls a retriever model on demand (Step 1).", "slice": "natural_answerable"}
{"case_id": "NAT_0189", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"It usually provides an extra knowledge source from a specific corpus, i.e., Wikipedia, which greatly improves the per- formance of LMs in a variety of tasks, especially in the [BLANK] ones.\"?", "gold": "knowledge-intensive", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 19, "relevant_text": "It usually provides an extra knowledge source from a specific corpus, i.e., Wikipedia, which greatly improves the per- formance of LMs in a variety of tasks, especially in the knowledge-intensive ones.", "slice": "natural_answerable"}
{"case_id": "NAT_0190", "query": "According to the paper 'raptor recursive abstractive processing for tree organized retrieval', what exact term completes this statement: \"3 M ETHODS Overview of RAPTOR Building on the idea that long texts often present subtopics and hierarchi- cal [BLANK] (Cao & Wang, 2022; Dong et al., 2023b), RAPTOR addresses the issue of semantic depth and connection in\"?", "gold": "structures", "relevant_doc_id": "2401.18059__raptor_recursive_abstractive_processing_for_tree_organized_retrieval.txt", "relevant_chunk_id": 21, "relevant_text": "3 M ETHODS Overview of RAPTOR Building on the idea that long texts often present subtopics and hierarchi- cal structures (Cao & Wang, 2022; Dong et al., 2023b), RAPTOR addresses the issue of semantic depth and connection in", "slice": "natural_answerable"}
{"case_id": "NAT_0191", "query": "According to the paper 'refrag rethinking rag based decoding', what exact term completes this statement: \"Ablation studies in section 4 demonstrate thatthis [BLANK] achieving strong CPT performance.\"?", "gold": "recipeiscrucialfor", "relevant_doc_id": "2509.01092__refrag_rethinking_rag_based_decoding.txt", "relevant_chunk_id": 29, "relevant_text": "Ablation studies in section 4 demonstrate thatthis recipeiscrucialfor achieving strong CPT performance.", "slice": "natural_answerable"}
{"case_id": "NAT_0192", "query": "According to the paper 'retrieval augmented generation for knowledge intensive nlp tasks', what exact term completes this statement: \"It has obtained [BLANK] results on a diverse set of generation tasks and outperforms comparably-sized T5 models [32].\"?", "gold": "state-of-the-art", "relevant_doc_id": "2005.11401__retrieval_augmented_generation_for_knowledge_intensive_nlp_tasks.txt", "relevant_chunk_id": 23, "relevant_text": "It has obtained state-of-the-art results on a diverse set of generation tasks and outperforms comparably-sized T5 models [32].", "slice": "natural_answerable"}
{"case_id": "NAT_0193", "query": "According to the paper 'from local to global a graph rag approach to query focused summarization', what exact term completes this statement: \"” Sensemaking tasks require reasoning over “ connections (which can be among people, places, and events) in order to anticipate their [BLANK] and act effectively ” (Klein et al., 2006).\"?", "gold": "trajectories", "relevant_doc_id": "2404.16130__from_local_to_global_a_graph_rag_approach_to_query_focused_summarization.txt", "relevant_chunk_id": 7, "relevant_text": "” Sensemaking tasks require reasoning over “ connections (which can be among people, places, and events) in order to anticipate their trajectories and act effectively ” (Klein et al., 2006).", "slice": "natural_answerable"}
{"case_id": "NAT_0194", "query": "According to the paper 'recomp improving retrieval augmented lms with compression and selective augmentation', what exact term completes this statement: \"We achieve a compression rate of as low as 6% with minimal loss in performance for both tasks, significantly outperforming the off-the-shelf [BLANK] models.\"?", "gold": "summarization", "relevant_doc_id": "2310.04408__recomp_improving_retrieval_augmented_lms_with_compression_and_selective_augmentation.txt", "relevant_chunk_id": 3, "relevant_text": "We achieve a compression rate of as low as 6% with minimal loss in performance for both tasks, significantly outperforming the off-the-shelf summarization models.", "slice": "natural_answerable"}
{"case_id": "NAT_0195", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"The retriever Raims to retrieve the top- [BLANK] D={dr1, ..., d rk}that are relevant to the input Xfrom the corpus C.\"?", "gold": "kdocuments", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 25, "relevant_text": "The retriever Raims to retrieve the top- Kdocuments D={dr1, ..., d rk}that are relevant to the input Xfrom the corpus C.", "slice": "natural_answerable"}
{"case_id": "NAT_0196", "query": "According to the paper 'recomp improving retrieval augmented lms with compression and selective augmentation', what exact term completes this statement: \"Although we do not have human annotations to train this model, prior work (Goyal et al., 2022; Chen et al., 2023; Potluri et al., 2023) suggests that the extreme- scale LMs can generate good [BLANK] summaries when prompted carefully.\"?", "gold": "query-focused", "relevant_doc_id": "2310.04408__recomp_improving_retrieval_augmented_lms_with_compression_and_selective_augmentation.txt", "relevant_chunk_id": 21, "relevant_text": "Although we do not have human annotations to train this model, prior work (Goyal et al., 2022; Chen et al., 2023; Potluri et al., 2023) suggests that the extreme- scale LMs can generate good query-focused summaries when prompted carefully.", "slice": "natural_answerable"}
{"case_id": "NAT_0197", "query": "According to the paper 'replug retrieval augmented black box language models', what exact term completes this statement: \"Black-Box Language Models Figure 1, REPLUG is [BLANK] flexible and can be used with any existing black-box LM and retrieval model.\"?", "gold": "extremely", "relevant_doc_id": "2301.12652__replug_retrieval_augmented_black_box_language_models.txt", "relevant_chunk_id": 8, "relevant_text": "Black-Box Language Models Figure 1, REPLUG is extremely flexible and can be used with any existing black-box LM and retrieval model.", "slice": "natural_answerable"}
{"case_id": "NAT_0198", "query": "According to the paper 'leveraging passage retrieval with generative models for open domain question answering', what exact term completes this statement: \"Building on that [BLANK] and the advances in pretrain- ing of natural language processing models, Roberts et al.\"?", "gold": "observation", "relevant_doc_id": "2007.01282__leveraging_passage_retrieval_with_generative_models_for_open_domain_question_answering.txt", "relevant_chunk_id": 2, "relevant_text": "Building on that observation and the advances in pretrain- ing of natural language processing models, Roberts et al.", "slice": "natural_answerable"}
{"case_id": "NAT_0199", "query": "According to the paper 'atlas few shot learning with retrieval augmented language models', what exact term completes this statement: \"Here, we propose an alternative which gives slightly stronger results, which relies on the following [BLANK].\"?", "gold": "observation", "relevant_doc_id": "2208.03299__atlas_few_shot_learning_with_retrieval_augmented_language_models.txt", "relevant_chunk_id": 27, "relevant_text": "Here, we propose an alternative which gives slightly stronger results, which relies on the following observation.", "slice": "natural_answerable"}
{"case_id": "NAT_0200", "query": "According to the paper 'corrective retrieval augmented generation', what exact term completes this statement: \"To [BLANK] others to reproduce our results, we will publish all source code l\"?", "gold": "facilitate", "relevant_doc_id": "2401.15884__corrective_retrieval_augmented_generation.txt", "relevant_chunk_id": 14, "relevant_text": "To facilitate others to reproduce our results, we will publish all source code l", "slice": "natural_answerable"}
